{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1530, 2720, 3)\n"
     ]
    }
   ],
   "source": [
    "# Read data in\n",
    "file = np.load('output.npz')\n",
    "xIn = file['x']\n",
    "yIn = file['y']\n",
    "print(xIn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the place holder input for the images\n",
    "imageWidth = 1530\n",
    "imageHeight = 2730\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, imageHeight, imageWidth, 3])\n",
    "\n",
    "# setup placeholder input for labels\n",
    "y = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "\n",
    "# placeholder for batch norm training phase.\n",
    "trainPhase = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the batch norm function for use.\n",
    "decayRate = 0.99\n",
    "betaInit = tf.zeros_initializer(dtype=tf.float32)\n",
    "gammaInit = tf.ones_initializer(dtype=tf.float32)\n",
    "\n",
    "# batchNormLayer\n",
    "# Adds a batch normalization layer to to the filter.\n",
    "# x - input tensor\n",
    "# filterShape - shape of filter\n",
    "# num - the number to not have the same variable name for the gamma and beta variables.\n",
    "# filtType - the type of filter (conv, mult)\n",
    "def batchNormLayer(x, numChannels, num, filtType='conv'):\n",
    "    # assumed to be convlution filter\n",
    "\n",
    "    #define weight variables\n",
    "    gamma = tf.get_variable('gamma' + str(num), [numChannels], initializer=gammaInit)\n",
    "    beta = tf.get_variable('beta' + str(num), [numChannels], initializer=betaInit)\n",
    "\n",
    "    axes = []\n",
    "    if filtType == 'mult':\n",
    "        axes = [0]\n",
    "    else:\n",
    "        axes = [0,1,2]\n",
    "    #if len(filterShape) == 4:\n",
    "    #    axes = [0,1,2]\n",
    "    #else:\n",
    "    #    axes = [0]\n",
    "    \n",
    "    batch_mean, batch_variance = tf.nn.moments(x, axes)\n",
    "    \n",
    "    ema = tf.train.ExponentialMovingAverage(decay=decayRate)\n",
    "    #ema_apply_op = ema.apply([batch_mean, batch_variance])\n",
    "    #mean = ema.average(batch_mean)\n",
    "    #variance = ema.average(batch_variance)\n",
    "    \n",
    "    def mean_var_with_update():\n",
    "            ema_apply_op = ema.apply([batch_mean, batch_variance])\n",
    "            with tf.control_dependencies([ema_apply_op]):\n",
    "                return tf.identity(batch_mean), tf.identity(batch_variance)\n",
    "\n",
    "    mean, variance = tf.cond(trainPhase,\n",
    "                        mean_var_with_update,\n",
    "                        lambda: (ema.average(batch_mean), ema.average(batch_variance)))\n",
    "    \n",
    "    \n",
    "\n",
    "    normed = tf.nn.batch_normalization(x, mean, variance, beta, gamma, 0.000001)\n",
    "    return normed, gamma, beta, ema.average(batch_mean), ema.average(batch_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numConvLayers = 0\n",
    "# Define variable initilization\n",
    "normInit = tf.truncated_normal_initializer(0,.05, dtype=tf.float32)\n",
    "zeroInit = tf.constant_initializer(0.05, dtype=tf.float32)\n",
    "\n",
    "# define convolutional layer\n",
    "# x - the input tensor\n",
    "# filterShape - the shape of the filter (height, width, num channels output)\n",
    "# poolShape - the shape of the pooling (height width)\n",
    "def convLayer(x, filterShape, poolShape):\n",
    "    global numConvLayers\n",
    "    inputChannels = x.shape[3]\n",
    "    convFilt = tf.get_variable('filt' + str(numConvLayers), \\\n",
    "        [filterShape[0], filterShape[1], inputChannels, filterShape[2]], \\\n",
    "        initializer=normInit)\n",
    "    bias = tf.get_variable('bias' + str(numConvLayers), \\\n",
    "        [filterShape[2]], initializer=normInit)\n",
    "    \n",
    "    logit = tf.nn.conv2d(x, convFilt, strides=[1,1,1,1], padding='SAME') + bias\n",
    "    normed, gamma, beta, mean, variance = \\\n",
    "        batchNormLayer(logit, filterShape[2], numConvLayers)\n",
    "    layer = tf.nn.relu(normed)\n",
    "    pooled = tf.nn.max_pool(layer, \\\n",
    "                ksize=[1,poolShape[0], poolShape[1], 1], \\\n",
    "                strides=[1,poolShape[0], poolShape[1], 1], \\\n",
    "                padding='SAME')\n",
    "    \n",
    "    \n",
    "    numConvLayers += 1\n",
    "    return pooled, [convFilt, bias, gamma, beta, mean, variance]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_2:0\", shape=(?, 91, 51, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "variables = []\n",
    "\n",
    "# define inference\n",
    "layer1, tmp = convLayer(x, [3,3,128], [10,10])\n",
    "variables += tmp\n",
    "layer2, tmp = convLayer(layer1, [5,5,64], [3,3])\n",
    "variables += tmp\n",
    "print(layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:flow]",
   "language": "python",
   "name": "conda-env-flow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
